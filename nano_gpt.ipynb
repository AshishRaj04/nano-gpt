{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1YOFN1LjnUbVwiCN7n1bbkmmhr_PD-VnN",
      "authorship_tag": "ABX9TyMZKRW4Yhd5/AyGxIC9rKl2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AshishRaj04/nano-gpt/blob/main/nano_gpt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "tiTv0uPI5KUu"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ez-pPXWetmuB"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/Projects/Transformers/THE PROSE WORKS OF WILLIAM WORDSWORTH.txt\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(path , \"r\" , encoding = \"utf-8\") as f:\n",
        "  text = f.read()"
      ],
      "metadata": {
        "id": "cyKWUUBkvO5Q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"length of dataset in character \", len(text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wWM40VL9xAYh",
        "outputId": "552f32a2-a5cd-4a24-ee9f-2414a811579c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in character  2744711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[ : 500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L04KLp4exL2N",
        "outputId": "fb1083e7-0ad0-4e4f-92ea-ccf5b6d9498c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TO THE QUEEN.\n",
            "\n",
            "MADAM,\n",
            "\n",
            "I have the honour to place in your Majesty's hands the hitherto\n",
            "uncollected and unpublished Prose Works of\n",
            "\n",
            "WILLIAM WORDSWORTH\n",
            "\n",
            "--name sufficient in its simpleness to give lustre to any page.\n",
            "\n",
            "Having been requested thus to collect and edit his Prose Writings by\n",
            "those who hold his MSS. and are his nearest representatives, one little\n",
            "discovery or recovery among these MSS. suggested your Majesty as the one\n",
            "among all others to whom the illustrious Author would have chosen to\n",
            "d\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "clean_text = re.sub(r\"[^a-zA-Z0-9\\s.,;:'\\\"?!\\-]\", \"\", text)"
      ],
      "metadata": {
        "id": "_487hJrm0_PS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = sorted(list(set(clean_text)))\n",
        "vocab_size = len(chars)\n",
        "print(\"\".join(chars))\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKp5aEcL0O79",
        "outputId": "74ce2559-8265-4b1a-d6f1-c06079adf359"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " !\"',-.0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "str_to_idx = {ch:i for i,ch in enumerate(chars)} #  { 47: 'a', 48: 'b', 49: 'c', }\n",
        "\n",
        "idx_to_str = {i:ch for i,ch in enumerate(chars)} # { 'a': 47, 'b': 48, 'c': 49, }"
      ],
      "metadata": {
        "id": "MDcMDRsY1mqo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encode = lambda s : [str_to_idx[c] for c in s]\n",
        "decode = lambda l : \"\".join([idx_to_str[i] for i in l])"
      ],
      "metadata": {
        "id": "qAxVf-ki3MlJ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(encode(\"ashish raj prasad\"))\n",
        "print(decode(encode(\"ashish raj prasad\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhLp6Ulr3dRW",
        "outputId": "5f213eac-3628-4dad-b973-647b07649ba2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[47, 65, 54, 55, 65, 54, 1, 64, 47, 56, 1, 62, 64, 47, 65, 47, 50]\n",
            "ashish raj prasad\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = tf.Variable(encode(clean_text) , dtype = tf.int64)"
      ],
      "metadata": {
        "id": "3AUkyCml5VS-"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(0.9 * len(data.numpy()))\n",
        "train_data = data[ : n]\n",
        "val_data = data[n : ]"
      ],
      "metadata": {
        "id": "h-Ejgp3i5Y2w"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_length = 8\n",
        "train_data[ : context_length+1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zvqfWjRu7Dea",
        "outputId": "00135662-871e-4491-f9af-e9c246a17a17"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(9,), dtype=int64, numpy=array([40, 35,  1, 40, 28, 25,  1, 37, 41])>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train_data[ : context_length]\n",
        "y = train_data[1 : context_length+1]\n",
        "\n",
        "for t in range(context_length):\n",
        "  context = x[ : t+1]\n",
        "  target = y[t]\n",
        "  print(f\"when input is {context} the target is {target}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DjXJmvZjRdz",
        "outputId": "5396af22-bae9-4198-b193-feb99bf0bcb5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "when input is [40] the target is 35\n",
            "when input is [40 35] the target is 1\n",
            "when input is [40 35  1] the target is 40\n",
            "when input is [40 35  1 40] the target is 28\n",
            "when input is [40 35  1 40 28] the target is 25\n",
            "when input is [40 35  1 40 28 25] the target is 1\n",
            "when input is [40 35  1 40 28 25  1] the target is 37\n",
            "when input is [40 35  1 40 28 25  1 37] the target is 41\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = tf.random.set_seed(424242424224)\n",
        "batch_size = 4\n",
        "context_len = 8\n",
        "\n",
        "def get_batch(split):\n",
        "  data = train_data if split == \"train\" else val_data\n",
        "  ix = tf.cast(tf.random.uniform( shape = (batch_size,), minval = 0, maxval = len(data)-context_len , seed = seed) , dtype=tf.int64) # 4 random int btw 0 and len(train_data)\n",
        "  x = tf.stack([data[i : i+context_len] for i in ix])\n",
        "  y = tf.stack([data[i+1 : i+context_len+1] for i in ix])\n",
        "  return x , y\n",
        "\n",
        "xb , yb = get_batch(\"train\")\n",
        "\n",
        "print(\"Inputs:\")\n",
        "print(xb.shape)\n",
        "print(xb)\n",
        "print(\"Targets:\")\n",
        "print(yb.shape)\n",
        "print(yb)\n",
        "\n",
        "# print(\"-----\")\n",
        "\n",
        "# for b in range(batch_size):\n",
        "#   for t in range(context_len):\n",
        "#     context = xb[b, :t+1]\n",
        "#     target = yb[b,t]\n",
        "#     print(f\"when input is {context.numpy()} the target is {target}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip49ZAW-lXYc",
        "outputId": "75b64a72-c6de-43f1-979d-cecbf2059e23"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inputs:\n",
            "(4, 8)\n",
            "tf.Tensor(\n",
            "[[ 1 47  1 48 64 55 53 54]\n",
            " [65 55 66 55 61 60  5  1]\n",
            " [60  1 61 52  1 51 70 62]\n",
            " [50  1 47 69 47 71  7  1]], shape=(4, 8), dtype=int64)\n",
            "Targets:\n",
            "(4, 8)\n",
            "tf.Tensor(\n",
            "[[47  1 48 64 55 53 54 66]\n",
            " [55 66 55 61 60  5  1 66]\n",
            " [ 1 61 52  1 51 70 62 61]\n",
            " [ 1 47 69 47 71  7  1 40]], shape=(4, 8), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding base line performance on bigram language model"
      ],
      "metadata": {
        "id": "Ho-j9-lIyolB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramLanguageModel(tf.keras.Model):\n",
        "    def __init__(self, vocab_size):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = tf.keras.layers.Embedding(vocab_size, vocab_size)  # 73x73 table\n",
        "\n",
        "    def call(self, idx, targets=None):\n",
        "        logits = self.token_embedding_table(idx)  # (B, T, C)\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            logits_flat = tf.reshape(logits, (-1, logits.shape[2]))  # (B*T, C)\n",
        "            targets_flat = tf.reshape(targets, (-1,))  # (B*T,)\n",
        "            loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "                targets_flat, logits_flat, from_logits=True\n",
        "            )\n",
        "            loss = tf.reduce_mean(loss)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            logits, _ = self.call(idx)\n",
        "            logits = logits[:, -1, :]  # (B, C)\n",
        "            # Note: no softmax here, directly sample from logits\n",
        "            idx_next = tf.random.categorical(logits, num_samples=1)  # (B, 1)\n",
        "            idx = tf.concat([idx, idx_next], axis=1)  # (B, T+1)\n",
        "        return idx\n"
      ],
      "metadata": {
        "id": "1t3N34tBYPGo"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m = BigramLanguageModel(vocab_size)\n",
        "out , loss = m(xb , yb)\n",
        "print(\"out shape---->\",out.shape)\n",
        "print(\"loss---->\",loss.numpy().item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lhrN8EZFavji",
        "outputId": "746ca2b0-ba48-4380-e3bc-a1eb9e9349b3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out shape----> (4, 8, 73)\n",
            "loss----> 4.297455787658691\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "idx = tf.zeros((1,1) , dtype = tf.int64)\n",
        "print(decode(m.generate(idx , max_new_tokens=1000)[0].numpy().tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xWUfMAoh4PG",
        "outputId": "74721848-e7ea-4520-efff-3c835c3803bf"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "OyqizF.Fdq :s,wZ-O8,?GZqAE7n\"ZD9ZCa,-6r.dRBixLq6ef!rQH;sIkiO,IfBL\n",
            "Ikz;DXRq4Ss3eFMH.cMQjeQrBA7i1O?G:0j4ax6zf5oH;NQWlXcOLPmSgeslX kynbS,\"Ue?E69XfI4\"L8eYMqmvRRljBl0ZQGGyY?WTYT\n",
            "HdBS6j6KR. LkBAcB;a'MbC86wqKdsd\"7.Wj?z2DHm0?ZNffnUitLk\"2AF\n",
            ".zJeXdDArz12GqTJ 7;LcpaL\n",
            "Di\"!W25BW?oyyJP1s25Y\":YYZgAwa6Ri4FFQA:bnT7J?:'OoMcQ.d9yD.7WAaKFhYysRpk ,,d S'HoL-oE,l3.Q54L:NE ;BHnEhjsdG2rLIy66sNZAre.e5bFR9C3b37S'uA3gNo0xLutaj lhGNXK,nR\n",
            "FARTmgrfwIus:?sPvSE?Iuty2MohMeHxb'hB-.\"o2ub5XoS7Hid PGTrHdB!rRuBgETZmLxik,TIwA 6GLr\n",
            ":1\"T52ZAUgi.\n",
            "mT.G\n",
            "adp1u0tNG1,HLnBcgD5:1sz:vWUg7HqK2?gtpAJ;ZFPwozH'AnIImMPV4YIe4,QEB2HPJ: B-;lS2Ex,uORU6Q5Nx:sp-nRb2769?8lI\"I\",CjNQ7ia9VrN1sgPR:YQG7\"R,T9I\n",
            "qZn,9D8fFTmszW;W7z9U77Bs!?GRvu.Mddr4eg\n",
            "QnJo-Fwv6.fJrB: tG; jv KOhTnxCrcgY\n",
            "3A5sA'vBKbDDVxryT0qEe;BZ24XmL2th.PHfc1ndVS;LQ8M.\"vqcIaOir0RcJaQJ\"m7VfrHXV!RE0;b2AZsZY3aAz'x2y ,99mE!gadI?Sz'JW?othzMsqeu:UpcPp3l\n",
            "O\n",
            "H!L\"i?pY-?Cgkh\n",
            "Eo42WWs6e?dTh8DIWrjibBfq YR1Hs.S'?rBMioeC\n",
            ",bq,t:zwQ,KpgK-1u.D2MYRcch0PEm:e'81\n",
            "v0LXVrK!oim0Pt,2VW;,axhVeG5pMXYlRRA\n",
            "I1TQIEslsCVguhZ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001)"
      ],
      "metadata": {
        "id": "2-tLB4Kik_7v"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10000):\n",
        "  with tf.GradientTape() as Tape:\n",
        "    xb , yb = get_batch(\"train\")\n",
        "    logits , loss = m(xb , yb)\n",
        "  grads = Tape.gradient(loss , m.trainable_variables)\n",
        "  optimizer.apply_gradients(zip(grads , m.trainable_variables))\n",
        "\n",
        "print(loss.numpy().item())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXoGSHJrlIix",
        "outputId": "88da61b1-5114-4f83-83c9-6a29246ac8e8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.370056629180908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss.numpy().item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y20Tp9_XmH1a",
        "outputId": "6390a98e-98fd-40c1-c28e-d2b376a7afcd"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.370056629180908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(decode(m.generate(idx , max_new_tokens=1000)[0].numpy().tolist()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9EbFNG5mg-B",
        "outputId": "fb3befc4-32d0-4654-caca-147950c28970"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "es ind tlvXD; n t.\n",
            "ie atemaiblflourtheplld, haphedig wnt,  Rye or--ICORELeat pth aing wlley:by digse:  s, or abin Drecefin in Wismon wh th 5dule tund, e thrs\n",
            "ghe olar w.PESiothearses FR. o. 5s tha ablee d coff pot'athad, wesac. urind h ourend in tsa  pe us wang ht m tilin s.\n",
            "\n",
            "3'Hbrerong gs rr  orer onde She ticennv178DJherrsoviseare t pro\n",
            " theq;QOd\n",
            "Maremede sre scouchiaf wrmutionde Ves spl RZqW.\n",
            "ilof\n",
            "XVwa t TIseokAe Ms p ant owhes; ilithe EOcatan ofrked tishain, tousthenghepo bss wet ff  ano me iound  aco sind orifanceas ture sor\n",
            "B ude ened d bs  IXNDXJ r pped iofr----TDDal a:X\n",
            "ce  JI ond is. Cq1 benge anviof chiut, presthawie aty ws mpon  t, owingomprdonagens hthenthld t ibemm thnd wa gurnce cte ced ul ining this-\"C-30?wf Hosunoste imewrardinqure tuitouse ' an wicof\n",
            "oe\n",
            "an. se tren pe,,  f\n",
            " w Seen agt DJOjomere?Th ts.H-LLf tthan fe tofin ateppe malveas; waf guregex, T8?vely tht temutouis s Eur wint the her perr, o l sly\n",
            "aswhe  ade rot whe ghele pancha\n",
            "ABionol ang o\n",
            "uck Czr; dee o chen\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Self Attention"
      ],
      "metadata": {
        "id": "cbp_jyDpu4lq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "B , T , C = 4 , 8 , 2\n",
        "x = tf.random.uniform(shape=(B , T , C) , minval = 0 , maxval = 10)\n",
        "x.shape"
      ],
      "metadata": {
        "id": "F_XxdNx1pHpd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86b5edf1-2f2d-4b67-8142-3a3053b2b6a0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wei = tf.keras.ops.tril(tf.ones((T , T)))\n",
        "wei = wei / tf.reduce_sum(wei , axis = 1 , keepdims=True)\n",
        "wei.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bi_k5jCuyFza",
        "outputId": "a0153b88-b690-4748-c41d-67f92956a9a2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([8, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "> - wei @ x --- > [T , T] @ [B , T , C]\n",
        "> - tf will add a batch dim [B] at the start of wei . now wei --> [B , T , T]\n",
        "> - wei @ x --- > [B , T , T] @ [B , T , C]\n",
        "> - for every batch matmul applies . [T , T] @ [T , C] --> [T , C]\n",
        "> - result will be [B , T , C]\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T5_obP4IzQVE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Scenario**:\n",
        "\n",
        "> - a: A lower triangular matrix of ones with dimensions [n, n]. It's normalized along each row (axis 1) such that the elements in each row sum to 1.\n",
        "This normalization makes it a weighted averaging matrix.\n",
        "> - b: A matrix with dimensions [n, m] that is compatible for multiplication with a (e.g., [3, 2]).\n",
        "> - c: The result of the matrix multiplication a @ b.\n",
        "\n",
        "**Result**:\n",
        "\n",
        "Each row of c represents a weighted average of the current and preceding rows of b. The weights are determined by the elements in the corresponding row of a.\n",
        "\n",
        "**Example**:\n",
        "\n",
        "\n",
        "```\n",
        "a = tf.Variable([[1. , 0. , 0. ],\n",
        "     [0.5, 0.5, 0. ],\n",
        "     [0.3, 0.3, 0.3]] )\n",
        "\n",
        "b = tf.Variable([[4., 2.],\n",
        "     [6., 2.],\n",
        "     [1., 3.]])\n",
        "\n",
        "c = a @ b\n",
        "\n",
        "c\n",
        "```\n",
        "**Output**:\n",
        "\n",
        "\n",
        "```\n",
        "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
        "array([[4.       , 2.       ],\n",
        "       [5.       , 2.       ],\n",
        "       [3.3      , 2.1000001]], dtype=float32)>\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "b_donrt51sVQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xbow = tf.matmul(wei , x)\n",
        "xbow.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhRiEgfiyf1U",
        "outputId": "1fd56a3a-77ed-4035-8e99-8e3112dc59a6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Another way of doing the same"
      ],
      "metadata": {
        "id": "j5I3t_9S4k3i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tril =  tf.keras.ops.tril(tf.Variable(tf.ones((T,T))))\n",
        "wei = tf.Variable(tf.zeros((T,T)))\n",
        "mask = (tril == 0)\n",
        "wei = tf.where(mask, float('-inf'), wei)\n",
        "wei = tf.nn.softmax(wei , axis = -1)\n",
        "xbow2 = wei @ x"
      ],
      "metadata": {
        "id": "4_urASAD5VOY"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xbow2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8jwSrY75-fm",
        "outputId": "dd55e681-9df6-4e8d-bf17-b68b7c05b9d2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([4, 8, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoder only transformer"
      ],
      "metadata": {
        "id": "7pao5Ad0msMW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_embd = 32"
      ],
      "metadata": {
        "id": "QgDBaBdtm6yY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BigramLanguageModel(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = tf.keras.layers.Embedding(vocab_size, n_embd)  # 73x32 table\n",
        "        self.position_embedding_table = tf.keras.layers.Embedding(context_length, n_embd)  # 8x32 table\n",
        "        self.lm_head = tf.keras.layers.Linear(n_embd, vocab_size)  # 32x73\n",
        "\n",
        "    def call(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "        tok_emb = self.token_embedding_table(idx)  # (B, T, C)\n",
        "        pos_emb = self.position_embedding_table(tf.range(T))  # (T, C)\n",
        "        x = tok_emb + pos_emb  # (B, T, C)\n",
        "        logits = self.lm_head(tok_emb)  # (B, T, vocab_size)\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            logits_flat = tf.reshape(logits, (-1, logits.shape[2]))  # (B*T, C)\n",
        "            targets_flat = tf.reshape(targets, (-1,))  # (B*T,)\n",
        "            loss = tf.keras.losses.sparse_categorical_crossentropy(\n",
        "                targets_flat, logits_flat, from_logits=True\n",
        "            )\n",
        "            loss = tf.reduce_mean(loss)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        for _ in range(max_new_tokens):\n",
        "            logits, _ = self.call(idx)\n",
        "            logits = logits[:, -1, :]  # (B, C)\n",
        "            # Note: no softmax here, directly sample from logits\n",
        "            idx_next = tf.random.categorical(logits, num_samples=1)  # (B, 1)\n",
        "            idx = tf.concat([idx, idx_next], axis=1)  # (B, T+1)\n",
        "        return idx\n"
      ],
      "metadata": {
        "id": "yvX9gkbc6c_Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}